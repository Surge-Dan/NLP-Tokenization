# 双向匹配中文分词（NLP-Tokenization）
如何利用最大匹配算法进行中文分词。

# 目的
使用正向最大匹配算法、反向最大匹配算法和双向最大匹配算法进行中文分词。

输入为完整的句子，输出为分好词的句子。

# Usage
run main.py
